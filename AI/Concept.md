Optimizers:)
In machine learning, especially deep learning, optimizers are algorithms or methods used to change the weights and biases of the model to minimize the loss function.

Activation Functions in Neural Networks
Activation functions decide whether a neuron should be activated or not by introducing non-linearity into the output of a neural network.
They help neural networks learn complex patterns, like curves or boundaries, rather than just straight lines.

‚úÖ Choosing the Right Activation Function
Hidden layers - ReLU, LeakyReLU, Swish
Output (binary) - Sigmoid
Output (multi-class) - Softmax
Output (regression) - Linear (no activation)

Common Activation Functions
ReLU - Most used in hidden layers
Sigmoid - Binary classification (output layer)
Tanh - Better than sigmoid in some cases
Softmax-
Converts a vector into probability distribution
Multi-class classification (output)
Leaky ReLU - Fixes "dying ReLU" issue
ELU / SELU - Variants of ReLU for deeper nets or specific normalization needs
Swish - Smooth and powerful

What is a Neural Network?
A Neural Network is a computational model inspired by the human brain that is used to recognize patterns and solve complex problems such as image recognition, natural language processing, and even game playing.

1. What is a Perceptron?
A Perceptron is the simplest type of neural network ‚Äî a single-layer binary classifier.

2. The "Perceptron Trick"
The Perceptron Trick refers to how the weights are updated during training:

3. Limitations of the Perceptron
‚ùå Only works for linearly separable data
It cannot solve problems like XOR.
‚ùå Binary classification only
Original perceptron supports only two classes.
‚ùå Step function is not differentiable
You can't use gradient-based optimization (e.g. backpropagation).
‚ùå No probability
Outputs are hard class labels (0 or 1), not probabilities.

Multi-Layer Perceptron (MLP)
A Multi-Layer Perceptron (MLP) is a type of feedforward artificial neural network. Unlike the basic single-layer perceptron, an MLP has one or more hidden layers, enabling it to learn non-linear decision boundaries.

2. Key Properties
Deep vs. shallow-
1+ hidden layers = "deep" network
Non-linearity-
Allows modeling complex functions
Fully connected-
Every neuron in one layer connects to the next
Optimized-
Backpropagation and gradient descent

Loss Function in Neural Networks-
A loss function (also called cost function) measures how well a neural network‚Äôs predictions match the actual values. It's the objective we try to minimize during training.

Choosing the Right Loss
Regression - MSE / MAE
Binary classification - Binary Crossentropy
Multi-class (one-hot) - Categorical Crossentropy
Multi-class (integers) - Sparse Categorical Crossentropy

Gradient Descent
Gradient Descent is an optimization algorithm used to minimize the loss function in neural networks by updating model weights in the direction that reduces the loss.
Why Use Gradient Descent?
Neural networks have millions of parameters (weights and biases). Gradient Descent helps us find the best values for these parameters to reduce prediction error.

How Gradient Descent Works
Start with random weights.
Compute the loss using a loss function (e.g., MSE, crossentropy).
Calculate the gradient (‚àÇLoss/‚àÇweight): how much the loss changes with respect to a weight.
Update the weights in the opposite direction of the gradient:

Types of Gradient Descent
Batch-
Uses the entire dataset to compute gradients ‚Äî accurate but slow
Stochastic (SGD)-
Updates weights for each training example ‚Äî fast but noisy
Mini-Batch-
Updates weights using a subset (batch) of the data ‚Äî combines benefits of both

Vanishing Gradient Problem
The Vanishing Gradient Problem occurs when training deep neural networks ‚Äî especially those with many layers and sigmoid or tanh activations ‚Äî where the gradients become too small, effectively killing learning in earlier layers.
What Causes It?
When using backpropagation, we update weights by calculating the gradient of the loss with respect to each weight, using the chain rule.
If each partial derivative is a small number (e.g. from sigmoid or tanh), multiplying them across many layers shrinks the gradient exponentially.
No gradient = no weight updates = no learning for early layers.
Activation Functions That Cause It
Sigmoid-
Derivatives are between 0 and 0.25 ‚Üí vanishing gradient
Tanh-
Derivatives between 0 and 1, but still shrink over depth
Symptoms
Training accuracy saturates early
Loss stops decreasing
Earlier layers learn very slowly or not at all
Gradient values close to zero in early layers
üõ†Ô∏è Solutions
‚úÖ ReLU activation
Doesn't saturate for positive values; avoids vanishing gradient
‚úÖ Batch Normalization
Helps maintain stable distributions and gradients
‚úÖ Xavier/He initialization
Proper weight initialization prevents extreme shrinkage
‚úÖ Skip connections (ResNet)
Allow gradients to flow directly to earlier layers
‚úÖ Use LSTM/GRU
In RNNs, they are designed to avoid vanishing gradients


Gradient Clipping
Gradient Clipping is a technique used to prevent exploding gradients during training of deep neural networks ‚Äî especially RNNs, LSTMs, or any very deep models.
Why Use Gradient Clipping?
Sometimes, gradients during backpropagation become very large (i.e., explode), which causes:
Weights to update too aggressively
The loss to diverge (go to NaN or infinity)
Model fails to learn
Gradient Clipping caps the gradients to a maximum threshold so they don‚Äôt explode.
optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, clipnorm=1.0)
optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, clipvalue=0.5)
When to Use Gradient Clipping
RNNs / LSTMs-
Long sequences can cause gradient explosion
Deep CNNs / MLPs-
Can stabilize training in early epochs
GANs-
Discriminator gradients can explode
Reinforcement Learning-
Unstable feedback loops in training

What is Overfitting in Machine Learning?
Overfitting is when a machine learning model learns the training data too well, including its noise and outliers, and therefore fails to generalize to new, unseen data.
The model memorizes the training data instead of understanding the patterns.
Symptoms of Overfitting
High accuracy on training set
Low accuracy on validation/test set
The model performs poorly on real-world data

Dropout() ‚Üí Randomly drops neurons during training
kernel_regularizer=l2(...) ‚Üí L2 weight regularization
BatchNormalization() ‚Üí Stabilizes and accelerates training
EarlyStopping() ‚Üí Stops training when validation loss increases
1. Dropout
Randomly "drops out" (i.e., sets to zero) a fraction of the neurons during training so that the model doesn't become overly reliant on specific neurons.
from tensorflow.keras.layers import Dropout

model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))  # Drops 50% of neurons randomly during training
2. Early Stopping
Monitors validation loss during training and stops training when it starts to increase, which means the model has started to overfit.

3. Batch Normalization
Normalizes the inputs to a layer for each mini-batch, maintaining a stable distribution of activations throughout training.

4. Regularization (L1 & L2)
Regularization adds a penalty term to the loss function based on the magnitude of the model weights.
L1 Regularization (Lasso)
Adds absolute value of weights to the loss
Can drive some weights to exactly zero ‚Üí leads to sparsity
L2 Regularization (Ridge)
Adds squared value of weights to the loss
Penalizes large weights and keeps them small (smoother model)

What is Normalization in Machine Learning?
Normalization is the process of transforming input features so that they have a consistent scale. This ensures that no feature dominates simply due to its magnitude.
Normalization in Neural Networks
‚úÖ Input Normalization
‚úÖ Batch Normalization (Internal to Network)
Normalizes inputs within the network
Added as a layer after dense/conv layers

What is Hyperparameter Tuning?
Hyperparameter tuning is the process of choosing the best set of hyperparameters for a machine learning model to maximize its performance.
Unlike model parameters (which are learned during training), hyperparameters are set before training.
Methods of Hyperparameter Tuning
1. Grid Search (Exhaustive search)
2. Random Search
Faster than grid search. Tries a random combination of hyperparameters.
3. Bayesian Optimization (Efficient search)
Models the objective function and chooses next best parameter set

What is Ensemble Learning?
Ensemble Learning combines multiple machine learning models to improve accuracy, stability, and generalization over a single model.
Reduce bias, variance, or both by aggregating the predictions of multiple models.

What is Bagging (Bootstrap Aggregating)?
Bagging is a type of ensemble method that:
Trains multiple models on different random subsets (with replacement) of the training data.
Combines their predictions (e.g., by voting or averaging).
Random Forest is an ensemble of Decision Trees using Bagging.

Types of Ensemble Methods
Bagging-
Train base learners on random subsets
Random Forest
Boosting-
Train models sequentially, each fixing errors of the last
AdaBoost, Gradient Boosting, XGBoost
Stacking-
Combine different models using a meta-model
Logistic regression on top of RF + SVM

What is PCA?
PCA (Principal Component Analysis) is an unsupervised dimensionality reduction technique. It transforms high-dimensional data into a lower-dimensional space while retaining as much variance as possible.

Why Use PCA?
Reduce dimensionality for visualization or faster computation
Remove multicollinearity
Improve model performance
How PCA Works:
Standardize the data Center the data around mean 0 and scale to unit variance.
Compute the covariance matrix Understand how variables vary with respect to each other.
Compute eigenvectors and eigenvalues Eigenvectors = principal components Eigenvalues = amount of variance each component explains
Select top k components Based on cumulative explained variance.
Transform the original data Project it onto the selected components (new axes).

Practice
MLP-FNN
CNN
RNN-LSTM-GRU
GAN
AE-VAE

Concept:
Transformer
Diffusion model
Foundation model
Attention Mechanism
RAG
DBN
RBM
Optimizers
Activation Function/Loss Function
Gradient Descent 
Gradient Vanishing Problem
Gradient Clipping




########################################################

FeedForward NN:
A Forward Neural Network (also called a Feedforward Neural Network, or FNN) is the simplest type of artificial neural network in which information moves only in one direction‚Äîfrom the input layer, through hidden layers, to the output layer. There are no cycles or loops in this architecture.
A typical feedforward neural network consists of:
Input layer: Takes the input features.
Hidden layers: Perform transformations using weights and activation functions.
Output layer: Produces the final result (e.g., classification, regression).
Training (Using Backpropagation)
The network makes a prediction with forward pass.
A loss function compares prediction vs actual output.
Backpropagation calculates gradients of loss function and updates weights to minimize the loss using gradient descent.


Generative Adversarial Network:
The Generator takes in random noise and creates fake data (e.g., a fake image).
The Discriminator looks at both real data (e.g., real images) and fake data and tries to classify them as real or fake.
It learns the underlying data distribution by adjusting it's parameters through backpropogation
It's a Binary Classisfier and act as a Convolutional layer
The Generator tries to fool the Discriminator, while the Discriminator tries not to be fooled.
This adversarial process continues until the Generator gets so good that the Discriminator can‚Äôt tell real from fake.
Generator (G)
Tries to create fake data that looks real.
Discriminator (D)
Tries to distinguish real data from fake data created by the generator.
Noise ‚Üí [Generator] ‚Üí Fake Data ‚Üí [Discriminator] ‚Üí Real or Fake?                           
Generator - Learns to improve       
Discriminator - Learns to better detect fakes
Types of GAN-
1. Standard GAN (Vanilla GAN)
Structure: One Generator and one Discriminator
Loss: Binary Cross-Entropy (Minimax game)
2. Deep Convolutional GAN (DCGAN)
Enhancement: Uses Convolutional Neural Networks (CNNs) instead of fully connected layers.
Better for image generation.
3. Conditional GAN (cGAN)
Idea: Generator and Discriminator are both conditioned on extra information.
Allows controlled generation
4. Wasserstein GAN (WGAN)
Improves: Training stability by using Wasserstein (Earth Mover's) distance instead of JS divergence.
‚úÖ No more vanishing gradients.
‚úÖ Solves mode collapse issues.
‚ùó Requires weight clipping or gradient penalty.
5. StyleGAN / StyleGAN2 / StyleGAN3
By NVIDIA: Introduces a style-based generator architecture.
‚úÖ Generates highly realistic and controllable images (face generation, art, etc.).
‚úÖ Supports latent space editing (e.g., change hair color, age).
6. CycleGAN
For unpaired image-to-image translation.
Example: Horse ‚Üî Zebra, Summer ‚Üî Winter
Uses cycle consistency loss to train without paired data.
7. Pix2Pix
For paired image-to-image translation.
Example: Sketch ‚Üí Photo, Map ‚Üí Satellite
‚úÖ Requires paired training data.
Uses conditional GAN with L1 loss.
8. InfoGAN
Extends GANs to learn interpretable and disentangled representations.
Maximizes mutual information between latent variables and outputs.
9. BigGAN
Scalable GAN for high-resolution image generation on large datasets (like ImageNet).
Trained using large batch sizes and advanced stabilization tricks.
10. Progressive GAN (PGGAN)
Trains the model progressively, starting from low resolution (e.g., 4√ó4 ‚Üí 1024√ó1024).
‚úÖ More stable training and higher-quality images.
11. DualGAN / DiscoGAN
Designed for unsupervised image translation.
Similar to CycleGAN but with different architectures and loss terms.


Variational AutoEncoders:
A Variational Autoencoder (VAE) is a type of generative model that learns to represent data in a probabilistic latent space and can generate new data similar to what it has seen during training. VAEs are an extension of traditional autoencoders, but they incorporate ideas from Bayesian inference and variational methods.
Like an autoencoder, a VAE has:
An encoder: Maps input data to a latent (compressed) representation.
A decoder: Reconstructs the original data from the latent representation.
But unlike a regular autoencoder, the latent space in a VAE is probabilistic.
Use Cases of VAEs:
Image generation (e.g., handwritten digits, faces)
Anomaly detection
Data compression
Interpolation in latent space
Molecule and drug design

VAE vs GAN:
VAE-
Probabilistic & interpretable
Stable (uses likelihood-based loss)
Continuous & meaningful
Often blurry
GAN-
Sharp and realistic
Often unstable (minimax game)
Not explicitly regularized
High-quality, sharp images

Autoencoder:
An Autoencoder is a type of artificial neural network used to learn efficient representations (encodings) of data, typically for dimensionality reduction, denoising, or feature extraction. It's an unsupervised learning model that learns to compress and then reconstruct input data.
Encoder-
Compresses the input data into a lower-dimensional latent code
Decoder-
Reconstructs the original input from the latent code

Autoencoders vs VAE:
Autoencoder (AE)
Type-
Deterministic encoder-decoder
Probabilistic generative model
Latent Space-
Fixed latent vector zz
Distribution z‚àºN(Œº,œÉ2)z \sim \mathcal{N}(\mu, \sigma^2)
Purpose-
Data compression, denoising, feature extraction
Generating new data, probabilistic modeling
Output-
Reconstructed input
Reconstructed input (also enables sampling new data)
Latent representation-
Encoded as a point/vector zz
Encoded as a distribution ( q(z
Sampling-
Not used
Sampled from latent distribution using the reparameterization trick
Loss Function-
Mean squared error (MSE), Binary cross-entropy
MSE or BCE + KL divergence (regularizes latent space)
KL Divergence-
‚ùå No
‚úÖ Yes (pushes ( q(z
Generative Capabilities-
Limited / indirect
Designed for generating new samples directly

 
 
Backpropagation:
Backpropagation is the method of updating weights in a neural network by calculating the gradient of the loss function with respect to each weight, moving from the output layer backward to the input layer.
1. Forward Pass
Input data flows through the network layer by layer.
Output (prediction) is generated.
The loss function computes the error
2. Backward Pass (Backpropagation)
The loss is propagated backward through the network.
Using chain rule of calculus, compute the gradient (partial derivative) of the loss w.r.t. each weight.
The gradients show how much each weight contributed to the error.
3. Weight Update
Update each weight using Gradient Descent (or a variant like Adam)

Convolutional NN:
A Convolutional Neural Network (CNN) is a special type of deep learning neural network designed to process data with a grid-like structure, especially images. CNNs are highly effective in image recognition, object detection, and computer vision tasks.
Unlike traditional feedforward neural networks that use fully connected layers, CNNs use convolutional layers to automatically extract spatial features (edges, textures, shapes) from input images.
Key Components of a CNN
1. üß© Convolutional Layer
Applies filters (kernels) that slide over the input image. Each filter learns to detect a specific feature like edges, corners, or textures.
Output=Filter‚àóInput
2. üìâ Activation Function (ReLU)
Applies non-linearity:
ReLU(x)=max‚Å°(0,x)
3. üåÄ Pooling Layer
Reduces the size of feature maps (downsampling) while retaining important information.
Most common: Max Pooling
4. üß† Fully Connected Layer
After flattening the feature maps, this layer acts like a standard neural network to perform classification or regression.
üîÅ Flow of Data in a CNN
Input Image
    ‚Üì
[Convolution Layer + ReLU]
    ‚Üì
[Pooling Layer]
    ‚Üì
[Convolution Layer + ReLU]
    ‚Üì
[Pooling Layer]
    ‚Üì
[Flatten]
    ‚Üì
[Fully Connected Layer(s)]
    ‚Üì
Output (e.g., class probabilities)
üîç Example Use Case
For a handwritten digit image (like MNIST):
Input: 28√ó28 grayscale image
Convolutions: Detect curves, lines, shapes
Pooling: Reduce resolution
Fully Connected Layer: Predict digit class (0‚Äì9)

Recurrent Neural Network:
A Recurrent Neural Network (RNN) is a type of neural network specially designed to work with sequential data, such as time series, text, audio, or video frames. Unlike traditional feedforward neural networks, RNNs have memory‚Äîthey maintain a hidden state that captures information about previous inputs in the sequence.
Recurrence
RNNs loop over time: the output at time t depends not only on the input at time t, but also on the hidden state from time t‚àí1.
üìä Applications-
Text Generation
Writing like Shakespeare
Speech Recognition
Audio-to-text
Language Translation
English ‚Üí Hindi
Stock Price Prediction
Based on historical data
Chatbots
Remembering past conversation
‚ö†Ô∏è Problems with Basic RNNs-
Vanishing gradients
Exploding gradients
Short memory
Struggles with long-term dependencies
üß™ Solutions: Advanced RNNs-
LSTM (Long Short-Term Memory)
Handles long-term dependencies with gates
GRU (Gated Recurrent Unit)
Simpler and faster than LSTM, also effective

üß† Long Short-Term Memory (LSTM)?
LSTM is a special type of Recurrent Neural Network (RNN) designed to learn long-term dependencies and solve the vanishing gradient problem that occurs in traditional RNNs.
LSTM networks are widely used in NLP, time series forecasting, speech recognition, and sequence prediction tasks.
Regular RNNs forget long-range dependencies because they struggle to retain information over many time steps. LSTMs address this by adding gates that control the flow of information.
üß± LSTM Cell Architecture-
üîê Forget Gate
Decides what to forget from the previous state
‚úÖ Input Gate
Decides what new information to store
üß† Cell State
Acts as a memory track through time
üì§ Output Gate and Hidden State
Decides what to output at the current time step.
Decides what part of the memory becomes output.
An LSTM cell maintains two key states at every time step:
Cell State (ctc_tct‚Äã) ‚Äì Long-term memory
Hidden State (hth_tht‚Äã) ‚Äì Short-term output memory (also used for predictions)


üß† What is a Gated Recurrent Unit (GRU)?
A Gated Recurrent Unit (GRU) is a variant of the LSTM (Long Short-Term Memory) network, Like LSTM, it‚Äôs designed to handle sequential data and solve the vanishing gradient problem of traditional RNNs.
But unlike LSTM, GRU has a simpler architecture ‚Äî it uses fewer gates and is computationally faster, while still maintaining long-term dependencies.
üîë Key Components of GRU
Update Gate (ztz_tzt‚Äã)
Controls how much of the past information to keep
Reset Gate (rtr_trt‚Äã)
Controls how much past info to forget
It combines the cell state and hidden state into a single state vector (unlike LSTM which keeps them separate).
üß† Intuition
Update gate decides how much past information to carry forward.
Reset gate decides how much past information to forget.
GRU blends the old and new information to form the new state.

ü§ñ Transformers?
Transformers are a neural network architecture introduced in the landmark 2017 paper ‚ÄúAttention is All You Need‚Äù. They revolutionized how machines handle sequential data (like text) by using a mechanism called self-attention, completely removing the need for recurrence (RNNs, LSTMs, etc.).
üöÄ Key Features of Transformers-
Self-Attention
Allows the model to focus on different words in a sentence, regardless of position
Parallel Processing
Unlike RNNs, Transformers process sequences in parallel, making them much faster
Positional Encoding
Adds information about word positions to handle order (since there's no recurrence)
üîç Basic Architecture-
A Transformer model consists of:
1. Encoder
Takes input sequence (e.g., sentence).
Outputs a set of encoded representations.
2. Decoder
Takes encoder output + target sequence.
Generates the output (e.g., translated sentence).
Each encoder/decoder layer includes:
Multi-Head Attention
Allows the model to attend to different positions simultaneously
Feed-Forward Network
Applies non-linearity and transformation
Layer Normalization
Stabilizes training
Residual Connections
Helps gradients flow in deep networks
üß† Transformer-Based Models
BERT
GPT
T5
ViT
Whisper


Attention Mechanism?
The attention mechanism allows a model to dynamically focus on different parts of the input when generating an output.
‚úÖ Analogy:
When reading a sentence to translate it, you don‚Äôt look at all words equally‚Äîyou pay attention to the most relevant ones. That‚Äôs what attention does in a model.
üìä Basic Idea
Given:
Query (Q): What we‚Äôre focusing on (e.g., the current word being processed)
Key (K): Representations of all inputs
Value (V): The information you retrieve
What is Self-Attention?
Self-attention is a special case of attention within the same sequence ‚Äî it lets every word attend to every other word in the same input.
In Self-Attention, the Query, Key, and Value are all derived from the same input sequence.
Why is this powerful?
Captures dependencies between all words
Doesn‚Äôt care about distance between words
Allows parallel processing
What is Multi-Head Attention?
Instead of applying self-attention once, Multi-Head Attention applies it multiple times in parallel with different learnable projections.
Each "head" learns to focus on different aspects:
Subject-verb relationship
Word tense consistency
Semantic similarity
Mechanism:
Split input into multiple heads
Apply self-attention to each head independently
Concatenate and linearly combine the results
Attention
Focuses on relevant parts of input when producing output
Self-Attention
Every word attends to every other word in same sequence
Multi-Head Attention
Learns multiple perspectives at once; improves learning

What is RAG?
RAG (Retrieval-Augmented Generation) is a method where a language model retrieves external knowledge before generating a response.
Introduced by Facebook AI (Meta), RAG allows models to pull in factual or context-relevant data from a database, search index, or documents, improving accuracy, factual consistency, and up-to-dateness.
RAG stands for Retrieval-Augmented Generation. It‚Äôs a powerful architecture used in NLP (Natural Language Processing) that combines the strength of:
Retrieval-based systems (which fetch relevant documents or knowledge), and
Generative models (like GPT or BART, which generate natural language).
üîç How RAG Works
Step 1: Query Encoding
The input (e.g., a user question) is passed through a question encoder to create a vector embedding.
Step 2: Retrieval
The embedding is used to search a knowledge base (e.g., Wikipedia, vector DB like FAISS or Pinecone) to fetch the top-k most relevant documents.
Step 3: Context Fusion
Each retrieved document is combined with the original query and passed to a generator model (e.g., BART, T5).
Step 4: Generation
The generator outputs a response using both the question and the retrieved content.
üß© Components of RAG
Retriever
Finds relevant text chunks or documents
Generator
Uses the retrieved info to generate answers
Knowledge Base
External source (can be static or dynamic)

What is a Deep Belief Network?
A Deep Belief Network is a generative graphical model that learns to reconstruct input data by discovering hierarchical features layer by layer.
It combines unsupervised pretraining with supervised fine-tuning.
Structure of DBN-
A typical DBN consists of multiple layers of RBMs stacked on top of each other:
Each RBM:
Learns to encode features of the previous layer
Passes its output as input to the next layer
Restricted Boltzmann Machine (RBM) Basics
An RBM is a two-layer neural network:
Visible layer: Receives the input
Hidden layer: Learns to represent features
The layers are fully connected but have no connections within a layer
It is an energy-based model trained using a technique called Contrastive Divergence.
It learns the probability distribution of the input data.
How DBN Works (Training Process)
Step 1: Unsupervised Layer-Wise Pretraining
Train each RBM one at a time, from bottom to top.
Output of each RBM becomes input to the next.
Step 2: Supervised Fine-Tuning
After pretraining, add a classifier (e.g., softmax layer).
Fine-tune the entire network using backpropagation.

What is a Diffusion Model?
A Diffusion Model learns to generate new data (e.g. images) by simulating a gradual denoising process that starts from pure noise and ends in a realistic sample.
Forward Process (Noise): Gradually add noise to an image/data in many small steps until it becomes pure noise.
Reverse Process (Denoising): Learn to remove that noise step by step to generate a realistic image from noise.
Popular Diffusion Models
DDPM-
Stable Diffusion
DALL¬∑E 2
Imagen
MusicGen / AudioLM

Foundation Model
A Foundation Model is a large, general-purpose model trained on massive, diverse datasets (often using self-supervised learning) that can be adapted (fine-tuned or prompted) for specific tasks.
Key Characteristics-
Pretrained at Scale
General-Purpose
Adaptable
Multimodal Capable
Examples of Foundation Models
GPT-human like text, 
Generative pre-trained Transformer
BERT-understad context of words in search queris, Bidirectional Encoder Representations from Transformers
DALLE-image generation 


Projects:

























